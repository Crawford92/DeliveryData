{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f856851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import os\n",
    "from os import walk\n",
    "import pandas as pd\n",
    "import re\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import GPSTAGS, TAGS\n",
    "import numpy as np\n",
    "import pygsheets\n",
    "\n",
    "\n",
    "#Set this to 1 to see diagnostics\n",
    "displayDebugInfo = 0\n",
    "#Set this to 1 to export the resulting dataframe to Sheets\n",
    "exportFlag = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a6d0b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP ONE, get file names from the specified directory\n",
    "\n",
    "# Set a variable to the path of where screenshots are located, then grab all the file names in that directory\n",
    "dir1 = os.getcwd() + \"/ScreenShots\"\n",
    "# walk returns (current path, directories in current path, files in current path) so [2] returns the files\n",
    "# next is for error handling, but might not be necessary given the input context\n",
    "filenames = next(walk(dir1), (None, None, []))[2]\n",
    "filenames = sorted(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2358f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP TWO, extract EXIF data, create df of file name and time stamp\n",
    "\n",
    "# Only PNG screenshots are used, so experiencing errors here is unlikely, but error handling could be improved\n",
    "timestampList = []\n",
    "#fileNameList = []\n",
    "for file in filenames:\n",
    "    try:\n",
    "        #fileNameList.append(file)\n",
    "        file = dir1 + \"/\" + file\n",
    "        image = Image.open(file)\n",
    "        if image._getexif() == None:\n",
    "            #Ideally, remove file from filenames if error occurs\n",
    "            print(f\"{file} contains no exif data.\")\n",
    "        else:\n",
    "            for tag, value in image._getexif().items():\n",
    "                tag_name = TAGS.get(tag)\n",
    "                if tag_name == \"DateTimeOriginal\":\n",
    "                    timestampList.append(value)\n",
    "    except IOError:\n",
    "        #Ideally, remove file from filenames if error occurs\n",
    "        print(\"File format not supported!\", file)\n",
    "dfTuples = list(zip(filenames, timestampList))    \n",
    "timeDF = pd.DataFrame(dfTuples, columns=[\"FileName\", \"Time\"])\n",
    "\n",
    "\n",
    "# DEBUG #\n",
    "if displayDebugInfo:\n",
    "    display(timeDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "488311d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP THREE : \n",
    "### For each file, read text from file\n",
    "### Establish if image represents a delivery offer or completed delivery\n",
    "### Strips large amount of unwanted text (input screenshots often include image of map with street names, etc)\n",
    "### Add text as list, to list of values representing offers OR completions\n",
    "### Add file name to offer or completion list depending on contents\n",
    "### Return 4 lists: offer text, completion text, offer files, completion files\n",
    "\n",
    "def testFunc(files_to_process_list):\n",
    "    theList = []\n",
    "    completionList = []\n",
    "    offerFiles = []\n",
    "    compFiles = []\n",
    "    for file in files_to_process_list:\n",
    "        #file to image\n",
    "        img = cv2.imread(dir1 + \"/\" + file)\n",
    "        #image to text\n",
    "        data = pytesseract.image_to_string(img)\n",
    "        \n",
    "        # There are, to date, three classes of images.\n",
    "        # One for orders through Marketplace, one for orders through Drive, and one for completions\n",
    "        # Marketplace is in app, Drive is the white label solution\n",
    "        # \"Completed\" should only appear in images of completed deliveries\n",
    "        # \"Guaranteed\" should only appear in images from Marketplace offers\n",
    "        # \"items\" should only appear in images from Drive offers \n",
    "        \n",
    "        #MARKETPLACE DELIVERY OFFER\n",
    "        if(\"Guaranteed\" in data):\n",
    "            # Add file to offer list\n",
    "            # If $ found, strip text from before $, else store all text\n",
    "            offerFiles.append(file)\n",
    "            if(\"$\" in data):\n",
    "                position = data.index(\"$\")\n",
    "                textsplit = data[position:].splitlines()\n",
    "                while (\"\" in textsplit):\n",
    "                    textsplit.remove(\"\")\n",
    "                theList.append(textsplit)\n",
    "            else:\n",
    "                data = data.splitlines()\n",
    "                theList.append(data)\n",
    "        #DELIVERY COMPLETIONS\n",
    "        elif(\"Completed\" in data):\n",
    "            # For these images, extraction works better when filters are applied, so they are reread with filters\n",
    "            compFiles.append(file)\n",
    "            img = cv2.imread(dir1 + \"/\" + file)\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "            data = pytesseract.image_to_string(thresh, lang='eng',config='--psm 6')\n",
    "\n",
    "            # The below section works as before to exclude anything read from the map\n",
    "            if(\"$\" in data):\n",
    "                position = data.index(\"$\")\n",
    "                textsplit = data[position:].splitlines()\n",
    "                while(\"\" in textsplit):\n",
    "                    textsplit.remove(\"\")\n",
    "                completionList.append(textsplit)\n",
    "            else:\n",
    "                print(\"Error in\", file, \"$ not found\")\n",
    "                data = data.splitlines()\n",
    "                completionList.append(data)\n",
    "        #DRIVE DELIVERY OFFER\n",
    "        elif(\"item\" in data):\n",
    "            # The interface has a slightly different format, so split the text into list of lines and process later\n",
    "            offerFiles.append(file)\n",
    "            data = data.splitlines()\n",
    "            theList.append(data)                   \n",
    "        else:\n",
    "            print(file)\n",
    "            print(\"ERROR WITH THIS FILE\")\n",
    "    return theList, completionList, offerFiles, compFiles\n",
    "\n",
    "x = testFunc(filenames)\n",
    "offersList     = x[0]\n",
    "completionList = x[1]\n",
    "offerFiles     = x[2]\n",
    "compFiles      = x[3]\n",
    "\n",
    "# DEBUG #\n",
    "if displayDebugInfo:\n",
    "    print(\"Offer Files: \", offerFiles)\n",
    "    print(\"Completed Files: \", compFiles)\n",
    "    print(\"Text from offers: \", offersList)\n",
    "    print(\"Text from completions: \", completionList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ae0712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: OFFER PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30cdc3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4.1: for Marketplace delivery offers, strip text between \"Guaranteed\" and \"Customer dropoff\"\n",
    "# and for Drive offers, just move the data along\n",
    "# If something doesn't work out at this point, error should be caught for examination\n",
    "\n",
    "offer_value_list = []\n",
    "error_list = []\n",
    "for x in offersList:\n",
    "    indexA = 0\n",
    "    indexB = 0\n",
    "    startVal = endVal = 0\n",
    "    DriveOrderFlag = 0\n",
    "    # For every string in the list\n",
    "    for y in x:\n",
    "        # If Drive order, add string and break\n",
    "        if \"item\" in y:\n",
    "            offer_value_list.append(x)\n",
    "            DriveOrderFlag = 1\n",
    "            break\n",
    "            \n",
    "            \n",
    "        # If Marketplace order\n",
    "        if \"Guaranteed\" in y:\n",
    "            startVal = indexA\n",
    "        if \"Customer dropoff\" in y:\n",
    "            endVal = indexB\n",
    "        indexA +=1\n",
    "        indexB +=1\n",
    "        if endVal != 0:\n",
    "            offer_value_list.append(x[startVal: endVal+1])\n",
    "            break\n",
    "    if(endVal == 0 and DriveOrderFlag != 1):\n",
    "        print(\"Error found, printing diagnostics and updating error_list\", indexA, indexB, startVal, endVal)\n",
    "        error_list.append(x)\n",
    "\n",
    "# DEBUG #\n",
    "if displayDebugInfo:\n",
    "    print(\"Offer Values List: \", offer_value_list)\n",
    "    print(\"Error List: \", error_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2551dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4.2: Pulling strings with relevant values to front columns\n",
    "\n",
    "offerProcessDF = pd.DataFrame(offer_value_list)\n",
    "offerProcessDF.fillna(\"\", inplace=True)\n",
    "\n",
    "# Iterate through DF, in each row find a string that contains \"DoorDash pay\" \n",
    "# Then use that as an anchor point to bring other values towards front columns\n",
    "for col in offerProcessDF:\n",
    "    targetRow = targetCol = -1\n",
    "    for index, value in offerProcessDF[col].items():\n",
    "        if \"DoorDash pay\" in value:\n",
    "            targetRow = index\n",
    "            targetCol = col\n",
    "            offerVal = offerProcessDF[targetCol-2][targetRow]\n",
    "            mileVal = offerProcessDF[targetCol-4][targetRow]\n",
    "            restVal = offerProcessDF[targetCol-6][targetRow]\n",
    "            offerProcessDF.at[targetRow, 0] = offerVal + \" Guaranteed\"\n",
    "            offerProcessDF.at[targetRow, 1] = mileVal\n",
    "            offerProcessDF.at[targetRow, 3] = \"Pickup\"\n",
    "            offerProcessDF.at[targetRow, 4] = restVal\n",
    "            \n",
    "# DEBUG #\n",
    "if displayDebugInfo:\n",
    "    display(offerProcessDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "383f3938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.3: strip all text from string in first column aside into \"$#.##\" format\n",
    "def getDollarString(df):\n",
    "    index = 0\n",
    "    for x in df[0]:\n",
    "        if(\"$\" in x):\n",
    "            x = x.replace(\" \", \"\")\n",
    "            x = x.replace(\"+\", \"\")\n",
    "            a = x.index(\"$\")\n",
    "            b = x.index(\"Guaranteed\")\n",
    "            the_float = x[a:b]\n",
    "            df.at[index, 0] = the_float\n",
    "        index +=1\n",
    "getDollarString(offerProcessDF)\n",
    "\n",
    "# DEBUG #\n",
    "if displayDebugInfo:\n",
    "    display(offerProcessDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e55799e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.4: Extract mileage value and stack status into two new columns\n",
    "\n",
    "# NOTE: This checks for \"mi\" as a substring, but technically, it can show up as yards\n",
    "\n",
    "\n",
    "# At this point, one of two columns will have the mileage information, so they are combined and the value extracted\n",
    "# If the offer is part of a staggered stack, it is flagged in a new column with a 1\n",
    "def mi2fl(df, columns):\n",
    "    df[\"Mileage\"] = df[columns[0]] + \" \" + df[columns[1]]\n",
    "    df[\"Stacked Order\"] = 0\n",
    "    itr = 0\n",
    "    for x in df[\"Mileage\"]:\n",
    "        if( \"mi\" in x):\n",
    "            #REGEX: \\S+ is string, \\s+ is whitespace, so find 1 'word' appearing before 'mi'\n",
    "            match = re.search('(\\S+\\s+){1}(?=mi)', x)\n",
    "            df.at[itr, \"Mileage\"] = float(match.group(0))\n",
    "            if (\"Additional\" in x):\n",
    "                df.at[itr, \"Stacked Order\"] = 1\n",
    "        else:\n",
    "            df.at[itr, \"Mileage\"] = \"ERROR\"\n",
    "        itr +=1       \n",
    "mi2fl(offerProcessDF, [1,2])\n",
    "\n",
    "\n",
    "# DEBUG #\n",
    "if displayDebugInfo:\n",
    "    display(offerProcessDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3db8bbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error detected\n"
     ]
    }
   ],
   "source": [
    "# STEP 4.5: Extract one or two restaurant names from each row, store values in new columns\n",
    "\n",
    "# The main idea here, is to pull the restaurant name(s) from a range of four possible columns\n",
    "### A \"natural stack\" offer will have Pickup appear twice\n",
    "\n",
    "def getRestNames(df):\n",
    "    restNames = []\n",
    "    rest2Names = []\n",
    "    for index, row in df.iterrows():\n",
    "        restName = \"\"\n",
    "        rest2 = \"\"\n",
    "        if(\"Pickup\" in row[3]):\n",
    "            restName = row[4].replace(\"| \", \"\")\n",
    "            restNames.append(restName)\n",
    "            if(\"Pickup\" in row[5]):\n",
    "                rest2 = row[6]\n",
    "                rest2Names.append(rest2)\n",
    "            else:\n",
    "                rest2Names.append(rest2)\n",
    "        elif(\"Pickup\" in row[4]):\n",
    "            restName = row[5].replace(\"| \", \"\")\n",
    "            restNames.append(restName)\n",
    "            if(\"Pickup\" in row[6]):\n",
    "                rest2 = row[7]\n",
    "                rest2Names.append(rest2)\n",
    "            else:\n",
    "                rest2Names.append(rest2)\n",
    "        # If target values not found, store names as ERROR\n",
    "        else:\n",
    "            print(\"Error detected\")\n",
    "            restNames.append(\"ERROR\")\n",
    "            rest2Names.append(\"ERROR\")\n",
    "    df[\"RestNames\"] = restNames\n",
    "    df[\"Rest 2\"] = rest2Names \n",
    "getRestNames(offerProcessDF)\n",
    "\n",
    "# DEBUG #\n",
    "if displayDebugInfo:\n",
    "    display(offerProcessDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82bd6e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4.6: Extract useful columns into succinct dataframe\n",
    "offerProcessDF = offerProcessDF.rename(columns={0: \"Dollars\"})\n",
    "offerDF = offerProcessDF[[\"Dollars\", \"Mileage\", \"RestNames\", \"Rest 2\", \"Stacked Order\"]].copy()\n",
    "\n",
    "# DEBUG #\n",
    "if displayDebugInfo:\n",
    "    display(offerDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "015cfc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: Delivery Completions Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2b84b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5.1: List to DF, replace empty with empty string\n",
    "\n",
    "#cDF is processing dataframe for completions\n",
    "\n",
    "cDF = pd.DataFrame(completionList)\n",
    "cDF.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c22108b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5.2: Extract all relevant values to completedDF\n",
    "\n",
    "# NOTE: Due to the data extracted from these images being more structured than the text from offer images\n",
    "### the process was simpler\n",
    "\n",
    "\n",
    "# Index 1 is row index 2 is col \n",
    "# \"Customer Tips\" as anchor, if found anchorFlag set to 1\n",
    "\n",
    "\n",
    "completedDF = pd.DataFrame(columns = [\"Base Pay\", \"Tip\", \"Peak Pay\", \n",
    "                                          \"Restaurant Name\", \"Restaurant Name 2\", \"Tip 2\", \"Total\"])\n",
    "\n",
    "for index1, row in cDF.iterrows():\n",
    "    \n",
    "    # FLAGS #\n",
    "    anchorFlag = False\n",
    "    stackFlag = False\n",
    "    \n",
    "    # BASE CASE ELEMENT ATTRIBUTES\n",
    "    basePay = 0\n",
    "    tipPay = 0\n",
    "    peakPay = 0\n",
    "    totalPay = 0\n",
    "    rest2 = \"N/A\"\n",
    "    tip2 = \"N/A\"\n",
    "    \n",
    "    # Loop through entire dataframe\n",
    "    for index2, value in row.items():\n",
    "        if(\"Customer Tips\" in value):\n",
    "            anchorFlag = True\n",
    "            ############################ PEAK PAY INDEXING ##############################\n",
    "            if(\"Peak Pay\" in cDF[index2-1][index1]):\n",
    "                \n",
    "                # PEAK PAY SUB PROCESS #\n",
    "                peakPay = cDF[index2-1][index1]\n",
    "                if (\"$\" in peakPay):\n",
    "                    peakPay = peakPay[peakPay.index(\"$\"):] \n",
    "                else:\n",
    "                    peakPay = \"ERROR\"\n",
    "                \n",
    "                # RESTAURANT NAME + TIP SUBPROCESS #\n",
    "                restName = cDF[index2+1][index1]\n",
    "                if (\"$\" in restName):\n",
    "                    tipPay = restName[restName.index(\"$\"):]\n",
    "                    restName = restName[:restName.index(\"$\")]\n",
    "                else:\n",
    "                    tipPay = \"$0.00\"\n",
    "                    restName = restName[:restName.index(\"-\")]\n",
    "                    \n",
    "                # BASE PAY SUBPROCESS #\n",
    "                basePay = cDF[index2-2][index1]\n",
    "                basePay = basePay[basePay.index(\"$\"):]\n",
    "                \n",
    "                # TOTAL + RESTAURANT 2 + TIP 2 SUBPROCESS #\n",
    "                if(\"Total\" in cDF[index2+2][index1]):\n",
    "                    total = cDF[index2+2][index1]\n",
    "                    total = total[total.index(\"$\"):]\n",
    "                else:\n",
    "                    rest2 = cDF[index2+2][index1]\n",
    "                    if (\"$\" in rest2):\n",
    "                        tip2 = rest2[rest2.index(\"$\"):]\n",
    "                        rest2 = rest2[:rest2.index(\"$\")]\n",
    "                    else:\n",
    "                        tip2 = \"$0.00\"\n",
    "                    if(\"Total\" in cDF[index2+3][index1]):\n",
    "                        stackFlag = True\n",
    "                        total = cDF[index2+3][index1]\n",
    "                        total = total[total.index(\"$\"):]\n",
    "                    else:\n",
    "                        stackFlag = False\n",
    "                        print(\"ERROR 2\")\n",
    "                    if(\")\" in rest2):\n",
    "                        if not (\"(\" in rest2):\n",
    "                            rest2 = \"N/A\"\n",
    "                            tip2 = \"N/A\"\n",
    "                            stackFlag = False            \n",
    "            ################################## STANDARD INDEXING ##################################\n",
    "            else:\n",
    "                # PEAK PAY SUBPROCESS #\n",
    "                peakPay = \"$0.00\"\n",
    "                \n",
    "                # RESTAURANT NAME + TIP SUBPROCESS #\n",
    "                restName = cDF[index2+1][index1]\n",
    "                if (\"$\" in restName):\n",
    "                    tipPay = restName[restName.index(\"$\"):]\n",
    "                    restName = restName[:restName.index(\"$\")]\n",
    "                else:\n",
    "                    tipPay = \"$0.00\"\n",
    "                    \n",
    "                # BASE PAY SUBPROCESS #\n",
    "                basePay = cDF[index2-1][index1]\n",
    "                basePay = basePay[basePay.index(\"$\"):]\n",
    "                \n",
    "                # TOTAL + RESTAURANT 2 + TIP 2 SUBPROCESS #\n",
    "                if(\"Total\" in cDF[index2+2][index1]):\n",
    "                    total = cDF[index2+2][index1]\n",
    "                    total = total[total.index(\"$\"):]\n",
    "                else:\n",
    "                    rest2 = cDF[index2+2][index1]\n",
    "                    if (\"$\" in rest2):\n",
    "                        tip2 = rest2[rest2.index(\"$\"):]\n",
    "                        rest2 = rest2[:rest2.index(\"$\")]\n",
    "                    else:\n",
    "                        tip2 = \"$0.00\"\n",
    "                    if(\"Total\" in cDF[index2+3][index1]):\n",
    "                        stackFlag = True\n",
    "                        total = cDF[index2+3][index1]\n",
    "                        total = total[total.index(\"$\"):]\n",
    "                    else:\n",
    "                        stackFlag = False\n",
    "                        print(\"ERROR 2\")\n",
    "                    if(\")\" in rest2):\n",
    "                        if not (\"(\" in rest2):\n",
    "                            rest2 = \"N/A\"\n",
    "                            tip2 = \"N/A\"\n",
    "                            stackFlag = False\n",
    "    if not anchorFlag:\n",
    "        newRowList = [0, 0, 0, 0, 0, 0, 0]\n",
    "        completedDF.loc[len(completedDF)] = newRowList\n",
    "    else:\n",
    "        newRowList = [basePay, tipPay, peakPay, restName, rest2, tip2, total]\n",
    "        completedDF.loc[len(completedDF)] = newRowList\n",
    "        \n",
    "\n",
    "# DEBUG #\n",
    "if displayDebugInfo:\n",
    "    display(completedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36963df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: Join file name and timestamp to offersDF and completedDF\n",
    "\n",
    "# Adding file name of source image of data and timestamp to each row of offerDF\n",
    "offerDF[\"FileName\"] = offerFiles\n",
    "offerDF = offerDF.join(timeDF.set_index('FileName'), on=\"FileName\")\n",
    "offerDF = offerDF.rename(columns={\"Time\" : \"Offer Timestamp\"})\n",
    "offerDF = offerDF.drop([\"FileName\"], axis=1)\n",
    "\n",
    "# Adding file name of source image of data and timestamp to each row of completedDF\n",
    "completedDF[\"FileName\"] = compFiles\n",
    "completedDF = completedDF.join(timeDF.set_index('FileName'), on=\"FileName\")\n",
    "completedDF = completedDF.rename(columns={\"Time\" : \"Completed Timestamp\"})\n",
    "completedDF = completedDF.drop([\"FileName\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a163961",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# STEP 7: Join offers and completions together\n",
    "totalDF = completedDF.join(offerDF)\n",
    "\n",
    "# DEBUG #\n",
    "if displayDebugInfo:\n",
    "    display(totalDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20ce52f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 8: Pre-Export Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93e46b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 8.1: Convert strings with $ to floats\n",
    "\n",
    "testOutputDF = totalDF.copy()\n",
    "def dollarToFloatCols(df, cols):\n",
    "    for x in cols:\n",
    "        s = df[x].items()\n",
    "        for y in s:\n",
    "            #First, look for any values in the given columns with N/A, replace with 0.0\n",
    "            if(\"N/A\" in y):\n",
    "                df.at[y[0], x] = float(0.0)\n",
    "            #Next look for errors that replaced dollar values with 0\n",
    "            elif(y[1]==0):\n",
    "                df.at[y[0], x] = float(0.0)\n",
    "            #Next look for values that existed correctly with the $\n",
    "            elif(\"$\" in y[1]):\n",
    "                df.at[y[0], x] = float(y[1][y[1].index(\"$\")+1:])\n",
    "            # Error Handling\n",
    "            if not (isinstance(df.at[y[0], x], float)):\n",
    "                #print(\"ERROR AT:\", y[0], x, type(df.at[y[0], x]))\n",
    "                df.at[y[0], x] = float(0.0)\n",
    "                \n",
    "                \n",
    "colsForFunc = [\"Base Pay\", \"Tip\", \"Peak Pay\", \"Tip 2\", \"Total\", \"Dollars\"]\n",
    "dollarToFloatCols(testOutputDF, colsForFunc)\n",
    "testOutputDF = testOutputDF.astype({\"Base Pay\": 'float', \"Tip\": 'float', \"Peak Pay\": 'float', \n",
    "                                    \"Tip 2\": 'float', \"Total\": 'float', \"Dollars\" : 'float'})\n",
    "\n",
    "# DEBUG #\n",
    "if displayDebugInfo:\n",
    "    display(testOutputDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7f39d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 8.2: Convert rows with stacked orders to individual rows\n",
    "\n",
    "# At this point, only the second half of a staggered stack is flagged in the data, this flags both halves\n",
    "for index, row in testOutputDF.iterrows():\n",
    "    if row[\"Stacked Order\"] == 1:\n",
    "        testOutputDF.at[index-1, \"Stacked Order\"] = 1\n",
    "\n",
    "# The main idea:\n",
    "# find rows with a natural stack\n",
    "# extract and establish values for new row\n",
    "# update old row\n",
    "\n",
    "for index, row in testOutputDF.iterrows():\n",
    "    B_rest1 = row[\"RestNames\"]\n",
    "    B_rest2 = row[\"Rest 2\"]\n",
    "    A_rest1 = row[\"Restaurant Name\"]\n",
    "    A_rest2 = row[\"Restaurant Name 2\"]\n",
    "    \n",
    "    \n",
    "    if not B_rest2 == \"\":\n",
    "        errorFlag = False\n",
    "        \n",
    "        #### NEW ROW VARS ######\n",
    "        newBase = row[\"Base Pay\"]/2\n",
    "        newTip = row[\"Tip 2\"]\n",
    "        newPeak = row[\"Peak Pay\"]\n",
    "        newRestaurantName = A_rest2\n",
    "        newRestaurantName2 = \"\"\n",
    "        newTotal = row[\"Total\"]\n",
    "        newTS_A = row[\"Completed Timestamp\"]\n",
    "        newDollars = row[\"Dollars\"]\n",
    "        newMileage = row[\"Mileage\"]\n",
    "        newRestName = \"\"\n",
    "        newRest2 = \"\"\n",
    "        newStackedFlag = 1\n",
    "        newTS_B = row[\"Offer Timestamp\"]\n",
    "        \n",
    "        ### OLD ROW VARS ######\n",
    "        oldRestaurantName = A_rest1\n",
    "        oldRestName = B_rest1\n",
    "        oldRestName2 = oldRest2 = \"\"\n",
    "        oldBase = row[\"Base Pay\"]/2\n",
    "        oldStackedFlag = 1\n",
    "        \n",
    "        # LOGIC SECTION\n",
    "        if B_rest1 in A_rest1:\n",
    "            newRestName = B_rest2\n",
    "        elif B_rest1 in A_rest2:\n",
    "            newRestName = B_rest1\n",
    "            oldRestName = B_rest2\n",
    "        elif B_rest2 in A_rest1:\n",
    "            newRestName = B_rest1\n",
    "            oldRestName = B_rest2\n",
    "        elif B_rest2 in A_rest2:\n",
    "            newRestName = B_rest2\n",
    "        else:\n",
    "            #print(\"Error\")\n",
    "            errorFlag = True\n",
    "            newRestaurantName = \"ERROR\"\n",
    "            newRestName = \"ERROR\"\n",
    "            oldRestaurantName = \"ERROR\"\n",
    "            oldRestName = \"ERROR\"\n",
    "            \n",
    "        if not errorFlag:\n",
    "            # The new index is .5 above the current index, which helps sneak the new row into the right position\n",
    "            \n",
    "            # NEW ROW #\n",
    "            newIndex = index + 0.5\n",
    "            testOutputDF.loc[newIndex] = newBase, newTip, newPeak, newRestaurantName, newRestaurantName2, 0.0, newTotal, newTS_A, newDollars, newMileage, newRestName, newRest2, newStackedFlag, newTS_B    \n",
    " \n",
    "            # OLD ROW #\n",
    "            testOutputDF.at[index, \"Restaurant Name\"] = oldRestaurantName\n",
    "            testOutputDF.at[index, \"Restaurant Name 2\"] = oldRestName2\n",
    "            testOutputDF.at[index, \"RestNames\"] = oldRestName\n",
    "            testOutputDF.at[index, \"Rest 2\"] = oldRest2\n",
    "            testOutputDF.at[index, \"Base Pay\"] = oldBase\n",
    "            testOutputDF.at[index, \"Stacked Order\"] = oldStackedFlag\n",
    "            \n",
    "# re index the dataframe to maintain desired order\n",
    "testOutputDF = testOutputDF.sort_index().reset_index(drop=True)\n",
    "\n",
    "\n",
    "# DEBUG #\n",
    "if displayDebugInfo:\n",
    "    display(testOutputDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a040144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exportDeliveriesDF = testOutputDF[[\"RestNames\", \"Total\", \"Base Pay\", \n",
    "                                   \"Tip\", \"Peak Pay\", \"Stacked Order\", \"Offer Timestamp\", \"Mileage\",\n",
    "                                  \"Completed Timestamp\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e3cd1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 8.3: Extract Date, Start Time, and End Time\n",
    "\n",
    "# Because the timestamp is directly from exif data, it always has the same structure\n",
    "# yyyy:mm:dd hh:mm:ss\n",
    "\n",
    "\n",
    "# Extract Date\n",
    "dateFromDF = exportDeliveriesDF[\"Offer Timestamp\"][0]\n",
    "dateFromDF = dateFromDF[5:10] + \"/\" + dateFromDF[0:4]\n",
    "dateFromDF = dateFromDF.replace(\":\", \"/\")\n",
    "exportDeliveriesDF[\"Date\"] = dateFromDF\n",
    "\n",
    "# Extract Start and End Time\n",
    "exportDeliveriesDF[\"Start Time\"] = 1\n",
    "exportDeliveriesDF[\"End Time\"] = 1\n",
    "for index, value in exportDeliveriesDF.iterrows():\n",
    "    startTime = exportDeliveriesDF[\"Offer Timestamp\"][index]\n",
    "    startTime = startTime[11:16]\n",
    "    endTime = exportDeliveriesDF[\"Completed Timestamp\"][index]\n",
    "    endTime = endTime[11:16]\n",
    "    # Convert to 12 hour time from 24 hour\n",
    "    convertTo12HrFlag = 1\n",
    "    if(convertTo12HrFlag):\n",
    "        intA = int(startTime[0:2])\n",
    "        intB = int(endTime[0:2])\n",
    "        if(intA >= 13):\n",
    "            intA = intA-12\n",
    "        if(intB >= 13):\n",
    "            intB = intB-12\n",
    "        strA = str(intA)\n",
    "        strB = str(intB)\n",
    "        startTime = strA + startTime[2:5]\n",
    "        endTime = strB + endTime[2:5]\n",
    "        exportDeliveriesDF.at[index, \"Start Time\"] = startTime\n",
    "        exportDeliveriesDF.at[index, \"End Time\"] = endTime\n",
    "        \n",
    "\n",
    "# DEBUG #\n",
    "if displayDebugInfo:\n",
    "    display(exportDeliveriesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc4eb880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 8.4: Calculate Duration\n",
    "exportDeliveriesDF[\"Duration\"] = 0\n",
    "for index, value in exportDeliveriesDF.iterrows():\n",
    "    #if length = 4 do x, if 5 do y\n",
    "    endInt = value[\"End Time\"]\n",
    "    startInt = value[\"Start Time\"]\n",
    "    if(len(endInt) == 4):\n",
    "        endInt = int(endInt[2:5])\n",
    "    else:\n",
    "        endInt = int(endInt[3:6])    \n",
    "    if(len(startInt) == 4):\n",
    "        startInt = int(startInt[2:5])\n",
    "    else:\n",
    "        startInt = int(startInt[3:6])\n",
    "    durVal = endInt - startInt\n",
    "    if (durVal <= 0):\n",
    "        durVal = endInt + 60 - startInt\n",
    "    exportDeliveriesDF.at[index, \"Duration\"] = durVal\n",
    "    \n",
    "# DEBUG #\n",
    "if displayDebugInfo:\n",
    "    display(exportDeliveriesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94405b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 8.5: Setup pairing to be exported alongside Delivery DF\n",
    "rawDataDF = testOutputDF[[\"RestNames\", \"Restaurant Name\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e212d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 9: Export\n",
    "\n",
    "#Establishes link to G Sheet, pulls in the existing Deliveries data to be used in the next cell\n",
    "gc = pygsheets.authorize(service_file='file.json')\n",
    "sh = gc.open('DashData')\n",
    "sheets_DelDF       = sh[1].get_as_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0b0f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 9.1: Establish ID\n",
    "\n",
    "# Grab the most recent ID from Deliveries worksheet, add 1\n",
    "# Create array of ints from the previous value through the size of the dataframe to be exported \n",
    "# Establish new DF attribute for ID\n",
    "\n",
    "\n",
    "newIndexForExport = sheets_DelDF[\"ID\"].iloc[-1] + 1\n",
    "ID_array = np.arange(newIndexForExport, newIndexForExport+len(exportDeliveriesDF))\n",
    "exportDeliveriesDF[\"ID\"] = ID_array\n",
    "exportDeliveriesDF_1 = exportDeliveriesDF[[\"ID\", \"Date\", \"RestNames\", \"Total\", \"Base Pay\", \n",
    "                                          \"Tip\", \"Peak Pay\", \"Stacked Order\", \"Start Time\", \"Mileage\", \n",
    "                                          \"End Time\", \"Duration\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "460c1fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 9.2: Set Version to 3\n",
    "\n",
    "exportDeliveriesDF_1[\"Version\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "256d0abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 9.3: Replace Stacked Order flag with the ID of the delivery the order was stacked with\n",
    "\n",
    "secondHalf = False\n",
    "for index, value in exportDeliveriesDF_1.iterrows():\n",
    "    if secondHalf:\n",
    "        secondHalf = False\n",
    "        exportDeliveriesDF_1.at[index, \"Stacked Order\"] = value[\"ID\"] - 1\n",
    "    elif(value[\"Stacked Order\"] == 1):\n",
    "        secondHalf = True\n",
    "        exportDeliveriesDF_1.at[index, \"Stacked Order\"] = value[\"ID\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8972e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 9.4: Join export DF and raw data\n",
    "\n",
    "# I can understand why this might seem odd to do, but its nice to just have them side by side in sheets currently\n",
    "rawDataDF = rawDataDF.rename(columns={\"RestNames\":\"Name\", \"Restaurant Name\": \"raw data\"})\n",
    "exportDeliveriesDF_1 = exportDeliveriesDF_1.join(rawDataDF)\n",
    "\n",
    "# DEBUG #\n",
    "if displayDebugInfo:\n",
    "    display(exportDeliveriesDF_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77a8d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 9.5: Apply string mapping and export\n",
    "exportDeliveriesDF_1 = exportDeliveriesDF_1.applymap(str)\n",
    "if exportFlag:\n",
    "    wks = sh[7]\n",
    "    wks.set_dataframe(exportDeliveriesDF_1,(1,1))\n",
    "else:\n",
    "    exportDeliveriesDF_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
